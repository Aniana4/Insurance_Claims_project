---
title: "Claim Car Insurance"
author: "Montse Figueiro & Aniana González"
date: "6 de julio de 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##
The goal of this competition is to better predict Bodily Injury Liability Insurance claim payments based on the characteristics of the insured customer's vehicle.


* Cada Fila contiene la información anual sobre el seguro de un vehículo.  
* La variable "Claim_Amount" ha sido ajustada para tener en cuenta los efectos de las características no correspondientes al vehículo, pero pueden tener interacciones interesantes con las variables del vehículo.
* "Calendar_Year" es el año en el que el vehículo fué asegurado.
* "Household_ID" es la identificación del hogar, en un hogar puede haber más de un vehículo asegurado.
* "Vehicle" es el número que identifica al vehículo, pero el mismo vehículo no tiene porque tener el mismo número en los diferentes años.
* Tenemos para identifiar el vehículo Model_Year, Blind_Make (manufacturer), Blind_Model, Blind_Submodel.
* El resto de columnas contienen características del vehículo así como, otras características asociadas a la poliza. 
* Tenemos dos datasets:
    + Training de 2005-2007 para construir el modelo
    + Test de 2008-2009 sobre el que realizaremos las predicciones.

##Objetivo del Estudio

* Problema de Clasificación

Determinar que vehículos asegurados tendrán siniestros con daño corporal en los años 2008-2009, para ello utilizaremos el training dataset que nos aporta la información correspondiente a los años 2005-2006-2007, el cual volveremos a dividir en dos partes Training y Test data set para poder contrastar los resultados de la clasificación. Por último aplicaremos el modelo al Test dataset para 2008-2009.

    + K-vecinos (necesario normalizar)
    + Arboles de decisión (no necesario normalizar)
    + Bayes (Aprendizaje Probabilistico)
    + Random Forest
    + Validación: ROC, 

* Problema de Regresión

El objetivo del estudio es conseguir predecir en función de las características del vehículo los pagos por daño corporal ocasionados anualmente por cada vehículo.

    + Random Forest Regresión.
    + Previsión Datos numéricos - Métodos de Regresión
        + GLM
        + LM (PCA)
        + SVM
        + GBM
    + Neutral Networks
    
* Validación: Caret, ROC (visualización), Cross-validation, jackknife

Tipicamente en Seguros aplicamos los siguientes métodos:

Decision Trees, Random Forests, Gradient Boosting Machines, Neural Networks and Support Vector Machines

##Code Book Variables

[Dictionary](https://kaggle2.blob.core.windows.net/competitions-data/kaggle/2509/dictionary.html?sv=2012-02-12&se=2016-09-11T09%3A28%3A10Z&sr=b&sp=r&sig=LDorwQLrH%2BUJeduG58UByqlaxlatNMpte4iJZLhM0V8%3D)




##Lectura de Datos
```{}
library(data.table)
train <- fread("train_set.csv")
head (train)
test <- read.csv("test_set.csv")
str(train)
summary(train)
dim(train)
head(train)
```


###problema de memoria
library(pryr)

```{r}
memory.limit()
memory.limit(size=16384)
```

###Cambiamos los tipos de variables:

Las categóricas pasan a Factor, al igual que los años. 
```{r}
class(train)
train <- as.data.frame(train)
```

```{r}
str(train)
library(plyr)
train[6:20] <- lapply(train[6:20], as.factor) 
train$NVCat <- as.factor(train$NVCat)
train$OrdCat <- as.integer(train$OrdCat)
train$Model_Year <- as.factor(train$Model_Year)
train$Calendar_Year <- as.factor(train$Calendar_Year)
```
Añadir columna clasificación:
```{r}
train$classification <- ifelse(train$Claim_Amount==0,"0","1")
train$classification <- as.factor(train$classification)
```


##Visualización de Datos

Número de Pólizas por año
```{r}
count <- table(train$Calendar_Year)
df <- data.frame(group=names(count),count)
df$percent <-round((df$Freq/sum(df$Freq))*100,2)
df <- df[-1]
df
```
```{r}
slices <- df$Freq 
lbls <-df$Var1
pct <- df$percent
lbls <- paste("Año ",lbls, sep="")
lbls <- paste(lbls, pct,sep=": ") # add percents to labels 
lbls <- paste(lbls,"%",sep="") # ad % to labels 
pie(pct,labels = lbls, col=rainbow(length(lbls)),
  	main="Desglose Pólizas con Siniestro por Año")
```

Gráfico Variables categóricas - distribución tipo de variable:
```{r}
library(scales) 
gCat1 <- ggplot(train, aes(Cat1)) + 
 geom_bar(aes(Cat1, (..count..)/sum(..count..)), width=0.5, fill = "grey") 

gCat1 + scale_y_continuous(labels=percent) + xlab(NULL) + 
 ylab("% de tipos") + xlab("Tipos de Variable 1")+ggtitle("Distribución de las categorias") +  theme_bw()

gCat2 <- ggplot(train, aes(Cat2)) + 
 geom_bar(aes(Cat1, (..count..)/sum(..count..)), width=0.5, fill = "grey") 

gCat2 + scale_y_continuous(labels=percent) + xlab(NULL) + 
 ylab("% de tipos") + xlab("Tipos de Variable 1")+ggtitle("Distribución de las categorias") +  theme_bw()

```


Tabla missing Values:
```{r}
train[train=="?"] <- NA
Tabla_NAs <- as.data.frame(sapply(train, function(x) sum(is.na(x))))
colnames(Tabla_NAs) <- c("NumNAs")
obs_total <- nrow(train)
Tabla_NAs$Porcentaje <- round((Tabla_NAs$NumNAs/nrow(train))*100,2)
Tabla_NAs
```
Seleccionamos de la tabla solo los que tienen NAs:

```{r}
TablaNas_Positive <- Tabla_NAs[Tabla_NAs$NumNAs>0,]
TablaNas_Positive
```

Tabla con Valores más frecuentes para cada Variable Categórica:
```{r}
values <- sapply(train,function(x) max(table(x)))
values <- as.data.frame(values)
nombres <- sapply(train,function(x) names(which.max(table(x))))
nombresvar <- as.data.frame(nombres)
clasevar <- sapply(train,function(x) class(x))
clasevar <- as.data.frame(clasevar)
Tabla_var_frecuentes <- as.data.frame(rownames(nombresvar))
Tabla_var_frecuentes$Tipo <- nombresvar$nombres
Tabla_var_frecuentes$Observaciones <- values$values
Tabla_var_frecuentes$Clasevar <- clasevar$clasevar
colnames(Tabla_var_frecuentes) <- c("Variable","Tipomasfrecuente","Observaciones","Clase_variable")
Tabla_var_frecuentes <- Tabla_var_frecuentes[Tabla_var_frecuentes$Clase_variable=="factor",]
Tabla_var_frecuentes$Porcentaje <- round((Tabla_var_frecuentes$Observaciones/nrow(train))*100,2)
Tabla_var_frecuentes
```

##Tratamiento Missing values

Han sido borrados del Test dataset pero no del training dataset. Están como "?". 
Tenemos casillas en blanco
Hay 4 variables con más de 4 millones de NA's

Contamos los casos completos (no tienen ningún NA) y los casos incompletos (tienen algún NA)
```{r}
sum(complete.cases(train)) # Count of complete cases in a data frame named 'data'
sum(!complete.cases(train)) # Count of incomplete cases
```

Sumamos cuantos NA tiene cada observación:
```{r}
train$NAS <- rowSums(is.na(train))
train$NAS <- as.factor(train$NAS)

as.data.frame(summary(train$NAS))
```
3706301 casos no tienen NA y 3114961 tienen 1 NA.

```{r}
casoscon1NA <- train[train$NAS==1,]
Tabla1NAs <- as.data.frame(sapply(casoscon1NA, function(x) sum(is.na(x))))
colnames(Tabla1NAs) <- "1NA"
```
```{r}
casoscon2NA <- train[train$NAS==2,]
Tabla2NAs <- as.data.frame(sapply(casoscon2NA, function(x) sum(is.na(x))))
colnames(Tabla2NAs) <- "2NA"
Tabla1NAs$`2NA` <- Tabla2NAs$`2NA`
```
```{r}
casoscon3NA <- train[train$NAS==3,]
dim(casoscon3NA)
Tabla3NAs <- as.data.frame(sapply(casoscon3NA, function(x) sum(is.na(x))))
colnames(Tabla3NAs) <- "3NA"
Tabla1NAs$`3NA` <- Tabla3NAs$`3NA`
```
```{r}
casoscon4NA <- train[train$NAS==4,]
Tabla4NAs <- as.data.frame(sapply(casoscon4NA, function(x) sum(is.na(x))))
colnames(Tabla4NAs) <- "4NA"
Tabla1NAs$`4NA` <- Tabla4NAs$`4NA`
Tabla1NAs
```

Hay 8431 observaciones con 48 siniestros con daño corporal a los que les falta Blind_Make, Blind_Model y Blind_Submodel:
```{r}
obs_without_model <- train[is.na(train$Blind_Submodel),]
dim(obs_without_model)
```
Cuantos modelos de vehículos diferentes tenemos en la base de datos:
```{r}
cols_model <- c("Model_Year","Blind_Make","Blind_Model","Blind_Submodel","Cat1","Cat3","Cat4","Cat5","Cat6","Cat8","Cat9","Cat10","Cat11")
modelcar <- train[,cols_model]
modelcar$count <- 1
Difmodelcar <- aggregate(count~. ,modelcar,sum)
head(Difmodelcar[order(Difmodelcar$count),])
#El count me dice cuantos coches con las mismas caracteristicas existen. El primero solo hay 1, del segudo 771....
dim(Difmodelcar[Difmodelcar$Model_Year==2004,])
head(Difmodelcar)
dim(Difmodelcar)
```
Variable "OrdCat" con Missing Value:

```{r}
NAOrdCat <- train[is.na(train$OrdCat),]
head(NAOrdCat)
dim(NAOrdCAt)

``

#Analizar los datos de la poliza
head(train)
cols <- c("NVCat", "NVVar1","NVVar2","NVVar3","NVVar4", "Claim_Amount")
Bd_polizas <- train[,cols]
head(Bd_polizas)
dim(Bd_polizas)

#Me quedo con las del importe mayor de 0
ver <- Bd_polizas[Bd_polizas$Claim_Amount>0,]
class(Bd_polizas)
ver <- Bd_polizas[duplicated(polizasclaim$Claim_Amount),]
ver2 <- ver[ver$Claim_Amount>0,]
head(ver)

head(Bd_polizas[order(Bd_polizas$Claim_Amount),])

#Tengo 52 polizas distintas
Bd_polizas$count <- 1
Difpoliza <- aggregate(count~ NVCat + NVVar1 + NVVar2 + NVVar3 + NVVar4 ,Bd_polizas,sum)
head(Difpoliza[order(-Difpoliza$count),])
sum(Bd_polizas$Claim_Amount)
dim(Difpoliza)
tail(Difpoliza)




str(Bd_polizas)
Bd_polizas[order(Bd_polizas$NVCat,Bd_polizas$Claim_Amount),]
Bd_polizas <- Bd_polizas[Bd_polizas$NVCat=="A" &  Bd_polizas$Claim_Amount > 0,]
head(Bd_polizas)


install.packages("VIM")

data <- train[1:100000,]
library(VIM)
aggr_plot <- aggr(data, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(data), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))

#marginplot(data[c(,15)])
install.packages("mice")
library(mice)
tempData <- mice(data,m=5,maxit=50,meth='pmm',seed=500)
summary(tempData)
```

Número total de casos con daños corporal según el número de missing values
```{r}
head(train)
columnas <- c("Household_ID","Claim_Amount","classification","NAS")
Bd_dañocorporal <- train[,columnas]
Bd_dañocorporal$classification <- as.numeric(Bd_dañocorporal$classification-1)
NA_daño <- aggregate(cbind(Claim_Amount, classification)~NAS, data=Bd_dañocorporal, sum, na.rm=TRUE)
NA_daño$Claim_Amount <-format(NA_daño$Claim_Amount, scientific = FALSE)
NA_daño
```

¿que hacemos con los casos que tienen más de 5 Na's?

###Vamos a ordenar las columnas por missing value, para ver si existe algún patrón

newdata <- train[is.na(train$Cat1),]



##Eliminamos Vehículos Duplicados
Para ello quitamos las variables Id (Row_ID,Vehicle,Calendar_Year). Dejamos Household_ID para tener algún identificador de la póliza (éste Id es igual para todos los vehiculos de esa casa)
```{r}
Data_noId <- train
Data_noId[,c("Row_ID","Vehicle","Calendar_Year")] <- NULL
Data_noduplicados <- Data_noId[!duplicated(Data_noId),]
Data_duplicados <- Data_noId[duplicated(Data_noId),]
sum(Data_noduplicados$Claim_Amount)
#Total 17.939.315 coincide con el total del fichero Train
anyDuplicated(Data_noduplicados)#0
sum(Data_noduplicados)
```
Tenemos vehículos duplicados pero cuyas Cat10,Cat11 y Cat12 varian en los diferentes año.


##Relaciona dos variables categóricas
cor(train$Calendar_Year,train$)
spineplot(train$Calendar_Year,train$Cat2)
spineplot(train$Calendar_Year,train$Cat3)
spineplot(train$Calendar_Year,train$Cat4)


##Muestra de Datos

El fichero "Train" que contiene datos de 2005, 2006 y 2007 tiene 13.184.290 observaciones y 35 columnas. De los cuales 95.605 han tenido siniestro con daño corporal.
```{r}
positiveclaim <- train[train$Claim_Amount>0,]
dim(positiveclaim)
```

Vamos a tomar una muestra del fichero "train" para trabajar los diferentes modelos y finalmente aplicarlo al fichero completo. Cogemos las 5.000.000 primeras filas.

```{r}
train_sample <- train[1:100000,]
class(train_sample)
train_sample <- as.data.frame(train_sample)
str(train_sample)
```


```{r}
library(plyr)
train_sample[6:20] <- lapply(train_sample[6:20], as.factor) 
train_sample$NVCat <- as.factor(train_sample$NVCat)
train_sample$OrdCat <- as.integer(train_sample$OrdCat)
train_sample$Model_Year <- as.factor(train_sample$Model_Year)
train_sample$Calendar_Year <- as.factor(train_sample$Calendar_Year)
```



Cuando el fichero ya está limpio lo divido en dos partes:

- 80000 observaciones "train"
- 20000 observaciones "test"

##KNN utilizando variables numéricas

```{r}
summary(train)
names(train_sample)
cols <- c("Var1","Var2","Var3","Var4","Var5","Var6","Var7","Var8")
claims <- c("classification")
data_num <-train_sample[,cols]
head(data_num)
data_num_labels <- train$Claim_Amount[1:100000]
data_num_labels <- ifelse(train$Claim_Amount==0,"0","1")
data_num_labels <- as.factor(data_num_labels)
train_set_labels <- data_num_labels[1:80000]
test_set_labels <- data_num_labels[80001:100000]
library(class)
train_set <-data_num[1:80000,] 
test_set <- data_num[80001:100000,]
summary(train_set)
normalize <- function(x){return ((x-min(x))/(max(x)-min(x)))}
train_set_norm <- as.data.frame(lapply(train_set,normalize))
test_set_norm <- as.data.frame(lapply(test_set,normalize))
test_set[is.na(test_set$Cat8),] <- "A"
train_set[is.na(train_set$Cat8),] <- "A"
summary(test_set$Cat8)

prediccion <- knn(train=train_set,test=test_set,cl=train_set_labels,k=15)
table(prediccion)
```



#Clasificación K-vecinos (KNN)

El algoritmo KNN requiere que todas las variables sean categóricas o continuas. Enel caso de tener de los dos tipos, las categóricas deben ser transformadas a numéricas antes de aplicar el algoritmo. En el caso de que las categóricas tengan más de dos categorías usaremos variables dummy.
cor(train_sample)
```{r}
library(caret)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
head(train_sample)
class(train_sample)

pruebaknn <- train_sample[,c("Var1","Var2","Var3","Var4")]
class(pruebaknn$Cat1)
levels <- train_sample[,35]

levels <- ifelse(levels==0,"0","1")
levels <- as.factor(levels)
unique(levels)
count(levels)

pruebaknn_train <- pruebaknn[1:4000000,]
pruebaknn_test <- pruebaknn[4000001:5000000,]

train_levels <- levels[1:4000000]
test_levels <- levels[4000001:5000000]
class(test_levels)
pred <- knn(train=pruebaknn_train,test=pruebaknn_test,cl=train_levels,k=3,use.all = FALSE)
header <- unlist(strsplit(colnames(dummies), '[.]'))[2 * (1:ncol(dummies))]
Cat1 <- factor(dummies %*% 1:ncol(dummies), labels = header)
```
str(train_sample)
* Necesitamos normalizar los datos
* El objetivo es clasificar los datos en "si" tienen daño corporal o "no" tiene daño corporal




#problema de memoria
library(pryr)

```{r}
memory.limit()
object_size(train)
memory.limit(size=16384)
```
##Substituimos el importe por 0 o 1 (no importe - si importe)
prueba <- train[sample(nrow(train), 100000), ]
sum(prueba$Claim_Amount)
prueba$damage <- ifelse(prueba$Claim_Amount==0,"0","1")
prueba$damage <- as.factor(prueba$damage)
sum(prueba$Claim_Amount!=0)
sum(prueba$Claim_Amount)

###Número de casos con daño corporal.
sum(train$Claim_Amount==0)
sum(train$Claim_Amount!=0)
sum(prueba$Claim_Amount!=0)

#Vamos a trabajar inicialmente sobre una muestra de 2 millones de observaciones:
````{r}
train_sample <- train[sample(nrow(train), 2000000), ]
train_sample <- as.data.frame(train_sample)
dim(train_sample)
str(train_sample)

```


#Comprobacion filas duplicadas
```{r}
anyDuplicated(train_sample)
train_sample[duplicated(train_sample),]
head(train_sample)
```
##densidad

```{r}
install.packages("tigerstats")
library(tigerstats)
quantile(train_sample$Claim_Amount)
summary(train_sample$Claim_Amount)
quantile(train_sample$Claim_Amount,probs=c(0.85,0.99,1))
nrow(train_sample)
positiveclaim <- train_sample[train_sample$Claim_Amount>0,]
nrow(positiveclaim)

##Correlaciones entre variables???
cor(train_sample$Var1,train_sample$Var2)
cor(train_sample$Var1,train_sample$Var6)
CrossTable(x=train_sample$Cat1,y=train_sample$Cat2)

#de 2000000 solo 14517 han tenido siniestro, esto es el 0.7%
densityplot(~Claim_Amount,data=train_sample,
       xlab="Importe Reclamacion",
       main="Densidad Reclamaciones")
boxplot(train_sample$Claim_Amount,main="Importe Siniestros Daño Corporal",ylab="Importe")
```

write.csv(train, file = "train_clean.csv")
#Tratamiento?
str(train)
summary(train_sample$Blind_Make)

