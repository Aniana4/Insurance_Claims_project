---
title: "Claim Car Insurance"
author: "Montse Figueiro & Aniana González"
date: "6 de julio de 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##
The goal of this competition is to better predict Bodily Injury Liability Insurance claim payments based on the characteristics of the insured customer's vehicle.


* Cada Fila contiene la información anual sobre el seguro de un vehículo.  
* La variable "Claim_Amount" ha sido ajustada para tener en cuenta los efectos de las características no correspondientes al vehículo, pero pueden tener interacciones interesantes con las variables del vehículo.
* "Calendar_Year" es el año en el que el vehículo fué asegurado.
* "Household_ID" es la identificación del hogar, en un hogar puede haber más de un vehículo asegurado.
* "Vehicle" es el número que identifica al vehículo, pero el mismo vehículo no tiene porque tener el mismo número en los diferentes años.
* Tenemos para identifiar el vehículo Model_Year, Blind_Make (manufacturer), Blind_Model, Blind_Submodel.
* El resto de columnas contienen características del vehículo así como, otras características asociadas a la poliza.
* Las variables numéricas han sido normalizadas, tienen media 0 y desviación standar 1.
* Tenemos dos datasets:
    + Training de 2005-2007 para construir el modelo
    + Test de 2008-2009 sobre el que realizaremos las predicciones.

##Objetivo del Estudio

* Problema de Clasificación

Determinar que vehículos asegurados tendrán siniestros con daño corporal en los años 2008-2009, para ello utilizaremos el training dataset que nos aporta la información correspondiente a los años 2005-2006-2007, el cual volveremos a dividir en dos partes Training y Test data set para poder contrastar los resultados de la clasificación. Por último aplicaremos el modelo al Test dataset para 2008-2009.

    + K-vecinos (necesario normalizar)
    + Arboles de decisión (no necesario normalizar)
    + Bayes (Aprendizaje Probabilistico)
    + Random Forest
    + Validación: ROC, 

* Problema de Regresión

El objetivo del estudio es conseguir predecir en función de las características del vehículo los pagos por daño corporal ocasionados anualmente por cada vehículo.

    + Random Forest Regresión.
    + Previsión Datos numéricos - Métodos de Regresión
        + GLM
        + LM (PCA)
        + SVM
        + GBM
    + Neutral Networks
    
* Validación: Caret, ROC (visualización), Cross-validation, jackknife

Tipicamente en Seguros aplicamos los siguientes métodos:

Decision Trees, Random Forests, Gradient Boosting Machines, Neural Networks and Support Vector Machines

##Code Book Variables

[Dictionary](https://kaggle2.blob.core.windows.net/competitions-data/kaggle/2509/dictionary.html?sv=2012-02-12&se=2016-09-11T09%3A28%3A10Z&sr=b&sp=r&sig=LDorwQLrH%2BUJeduG58UByqlaxlatNMpte4iJZLhM0V8%3D)




##Lectura de Datos
```{}
library(data.table)
train <- fread("train_set.csv")
test <- read.csv("test_set.csv")
str(train)
summary(train)
```

###problema de memoria
library(pryr)

```{r}
memory.limit()
memory.limit(size=45960)
```

###Cambiamos los tipos de variables:

Las categóricas pasan a Factor: 
```{r}
class(train)
train <- as.data.frame(train)
```

```{r}
library(plyr)
train[6:20] <- lapply(train[6:20], as.factor) 
train$NVCat <- as.factor(train$NVCat)
train$OrdCat <- as.factor(train$OrdCat)
```

Tenemos el año de la póliza y el año del vehículo, hemos comprobado que ninguna de las variables numérica se corresponde con la antigûedad del coche pero podemos calcularla y puede ser un dato muy interesante:

```{r}
train$EdadVehiculo <- as.numeric(train$Calendar_Year-train$Model_Year)
```
¿normalizamos la edadvehiculo?

Tenemos valores negativos en la edad del vehículo, es decir que si el año de la póliza es 2005 el año del modelo es 2006
Tenemos 155.991 coches con edades negativas,las vamos a dejar a 0 porque no tiene lógica 
```{r}
edad_negativa <- train[train$EdadVehiculo<0,]
summary(train$EdadVehiculo)
train$EdadVehiculo <- ifelse(train$EdadVehiculo < 0, 0, train$EdadVehiculo)
```



Podemos prescindir de las variables "Blind_Make" y "Blind_Model" porque están incluidas dentro de "Blind_Submodel", hemos comprobado que Blind_Submodel incluye Blind_Make y Blind_Model:

```{r}
pruebasubmodel <- train[train$Blind_Submodel=="K.2.4",]
summary(pruebasubmodel)
```
Pruebas desglose submodel
---------------------
train$largo <- nchar(levels(train$Blind_Make)[train$Blind_Make])
train$largo_model <- nchar(levels(train$Blind_Model)[train$Blind_Model])
train$largo_submodel <- nchar(levels(train$Blind_Submodel)[train$Blind_Submodel])
train$make <- ifelse(train$largo_submodel==5,substr(train$Blind_Submodel,1,3),ifelse(train$largo_submodel==6,substr(train$Blind_Submodel,1,4),ifelse(train$largo_submodel==7,substr(train$Blind_Submodel,1,5),ifelse(train$largo_submodel==8,substr(train$Blind_Submodel,1,6),"NA"))))
train$make <- as.factor(train$make)
str(train$Blind_Model)
str(train$make)
---------------------

##Visualización e imputación de NA's
```{r}
library(VIM)
library(mice)
```
##Tratamiento Missing values

Han sido borrados del Test dataset pero no del training dataset. Están como "?". 
Tenemos casillas en blanco???
Hay 4 variables con más de 4 millones de NA's

Sustituimos los "?" por NA:

```{r}
train[train=="?"] <- NA
```

Tabla resumen Missing Values por Variable:
```{r}
Tabla_NAs <- as.data.frame(sapply(train, function(x) sum(is.na(x))))
colnames(Tabla_NAs) <- c("NumNAs")
obs_total <- nrow(train)
Tabla_NAs$Porcentaje <- round((Tabla_NAs$NumNAs/nrow(train))*100,2)
Tabla_NAs
```
Seleccionamos de la tabla solo los que tienen NAs:

```{r}
TablaNas_Positive <- Tabla_NAs[Tabla_NAs$NumNAs>0,]
TablaNas_Positive
```


Tabla con Valores más frecuentes para cada Variable Categórica:
```{r}
values <- sapply(train,function(x) max(table(x)))
values <- as.data.frame(values)
nombres <- sapply(train,function(x) names(which.max(table(x))))
nombresvar <- as.data.frame(nombres)
clasevar <- sapply(train,function(x) class(x))
clasevar <- as.data.frame(clasevar)
Tabla_var_frecuentes <- as.data.frame(rownames(nombresvar))
Tabla_var_frecuentes$Tipo <- nombresvar$nombres
Tabla_var_frecuentes$Observaciones <- values$values
Tabla_var_frecuentes$Clasevar <- clasevar$clasevar
colnames(Tabla_var_frecuentes) <- c("Variable","Tipomasfrecuente","Observaciones","Clase_variable")
Tabla_var_frecuentes <- Tabla_var_frecuentes[Tabla_var_frecuentes$Clase_variable=="factor",]
Tabla_var_frecuentes$Porcentaje <- round((Tabla_var_frecuentes$Observaciones/nrow(train))*100,2)
Tabla_var_frecuentes
```


Contamos los casos completos (no tienen ningún NA) y los casos incompletos (tienen algún NA)
```{r}
sum(complete.cases(train)) # Count of complete cases in a data frame named 'data'
sum(!complete.cases(train)) # Count of incomplete cases
```

Sumamos cuantos NA tiene cada observación:
```{r}
train$NAS <- rowSums(is.na(train))
train$NAS <- as.factor(train$NAS)
freq_NA_row <- as.data.frame(summary(train$NAS))
freq_NA_row
```
3706301 casos no tienen NA y 3114961 tienen 1 NA.

```{r}
casoscon1NA <- train[train$NAS==1,]
Tabla1NAs <- as.data.frame(sapply(casoscon1NA, function(x) sum(is.na(x))))
colnames(Tabla1NAs) <- "1NA"
#Tenemos 2255420 en Cat2 y 849145 en Cat7
Tabla1NAs
```
```{r}
casoscon2NA <- train[train$NAS==2,]
Tabla2NAs <- as.data.frame(sapply(casoscon2NA, function(x) sum(is.na(x))))
colnames(Tabla2NAs) <- "2NA"
Tabla1NAs$`2NA` <- Tabla2NAs$`2NA`
```
```{r}
casoscon3NA <- train[train$NAS==3,]
Tabla3NAs <- as.data.frame(sapply(casoscon3NA, function(x) sum(is.na(x))))
colnames(Tabla3NAs) <- "3NA"
Tabla1NAs$`3NA` <- Tabla3NAs$`3NA`
```
```{r}
casoscon4NA <- train[train$NAS==4,]
Tabla4NAs <- as.data.frame(sapply(casoscon4NA, function(x) sum(is.na(x))))
colnames(Tabla4NAs) <- "4NA"
Tabla1NAs$`4NA` <- Tabla4NAs$`4NA`
Tabla1NAs
```

Hay 8431 observaciones con 48 siniestros con daño corporal a los que les falta Blind_Make, Blind_Model y Blind_Submodel:

```{r}
obs_without_model <- train[is.na(train$Blind_Submodel),]
dim(obs_without_model)
```
Cuantos modelos de vehículos diferentes tenemos en la base de datos:
```{r}
cols_model <- c("Model_Year","Blind_Make","Blind_Model","Blind_Submodel","Cat1","Cat3","Cat4","Cat5","Cat6","Cat8","Cat9","Cat10","Cat11","")
modelcar <- train[,cols_model]
modelcar$count <- 1
Difmodelcar <- aggregate(count~. ,modelcar,sum)
head(Difmodelcar[order(-Difmodelcar$count),])
```

Eliminamos las columnas que no necesitamos para las predicciones:

```{r}
train_df <- train[,4:36]
train_df$Blind_Make <- NULL
train_df$Blind_Model <- NULL
head(train_df)



gregadosubmodelo <- aggregate(Blind_Submodel~Cat1+Cat2+Cat3+Cat4+Cat5+Cat6+Cat7+Cat8+Cat9,train,length)
dim(agregadosubmodelo)
```
Vemos que 317 coches tienen los datos completos desde Cat1 a Cat9.



```

Añadir columna clasificación:
```{r}
train$classification <- ifelse(train$Claim_Amount==0,"0","1")
train$classification <- as.factor(train$classification)
```
##Comprobación de datos normalizados en variables numéricas (nosotros no hemos realizado la normalización pero tenemos que conocer que ha sido hecha):

```{r}
var_col <- c("Var1","Var2","Var3","Var4","Var5","Var6","Var7","Var8","NVVar1","NVVar2","NVVar3","NVVar4")
var_num <- train[,var_col]
round(sapply(var_num,function(x) mean(x)),0)
round(sapply(var_num,function(x) sd(x)),0)
```
##Visualización de Datos


Número de Pólizas por año
```{r}
count <- table(train$Calendar_Year)
df <- data.frame(group=names(count),count)
df$percent <-round((df$Freq/sum(df$Freq))*100,2)
df <- df[-1]
df
```
Pie Chart:
```{r}
slices <- df$Freq 
lbls <-df$Var1
pct <- df$percent
lbls <- paste("Año ",lbls, sep="")
lbls <- paste(lbls, pct,sep=": ") # add percents to labels 
lbls <- paste(lbls,"%",sep="") # ad % to labels 
pie(pct,labels = lbls, col=rainbow(length(lbls)),
  	main="Desglose Pólizas con Siniestro por Año")
```

Gráfico Variables categóricas - distribución tipo de variable:
```{r}
library(scales) 
gr2.a <- ggplot(train, aes(Cat1)) + 
 geom_bar(aes(Cat1, (..count..)/sum(..count..)), width=0.5, fill = "grey") 

gr2.a + scale_y_continuous(labels=percent) + xlab(NULL) + 
 ylab("% de tipos") + xlab("Tipos de Variable 1")+ggtitle("Distribución de las categorias") +  theme_bw()
```



summary(train$Row_ID)

Número total de casos con daños corporal según el número de missing values

```{r}
head(train)
columnas <- c("Household_ID","Claim_Amount","classification","NAS")
Bd_dañocorporal <- train[,columnas]
Bd_dañocorporal$classification <- as.numeric(Bd_dañocorporal$classification-1)
NA_daño <- aggregate(cbind(Claim_Amount, classification)~NAS, data=Bd_dañocorporal, sum, na.rm=TRUE)
NA_daño$Claim_Amount <-format(NA_daño$Claim_Amount, scientific = FALSE)
NA_daño
```

Las 4 últimas variables no son variables del vehículo, con lo que se corresponden con variables de la póliza, podemos analizar en que casos la póliza ha tenido cobertura para daño corporal.
```{r}
claim_poliza <- aggregate(Claim_Amount ~ NVCat + NVVar1 + NVVar2 + NVVar3 + NVVar4, data = train, FUN = length)
head(claim_poliza[order(-claim_poliza$Claim_Amount),])
dim(claim_poliza)
claim_poliza_amount <- aggregate(Claim_Amount ~ NVCat + NVVar1 + NVVar2 + NVVar3 + NVVar4, data = train, FUN = sum)
head(claim_poliza_amount[order(-claim_poliza_amount$Claim_Amount),])
claim_poliza_class <- aggregate(Claim_Amount ~ classification + NVCat + NVVar1 + NVVar2 + NVVar3 + NVVar4, data = train, FUN = length)
head(claim_poliza_class[order(-claim_poliza_class$Claim_Amount),])

```

##Visualización con VIM de las variables con NA:

```{r}
cols <- rownames(TablaNas_Positive)
cols_with_NA <- train[,cols]
head(cols_with_NA)
```
```{r}
jpeg("Missing_Pattern.jpeg")
train_aggr = aggr(cols_with_NA, numbers=TRUE, sortVars=TRUE, labels=names(cols_with_NA), cex.axis=.7, gap=3, ylab=c("Proportion of missingness","Missingness Pattern"))
dev.off()
```
Visualización solo de los que tienen Claim_Amount>0:
```{r}
positive_claims <- train[train$Claim_Amount>0,]
jpeg("Missing_Pattern_with_claim.jpeg")
train_aggr_claim = aggr(positive_claims, numbers=TRUE, sortVars=TRUE, labels=names(cols_with_NA), cex.axis=.7, gap=3, ylab=c("Proportion of missingness","Missingness Pattern"))
dev.off()
```
##Encontrar patrones de los Missing Values con "mice"


```{r}
train_sin_id <- train[,4:35]
muestra <- train_sin_id[1:10000,]
patrones_mice <- md.pattern(muestra)
```

##Imputación de los Missing Value con MICE

Tenemos 8431 observaciones que tienen missing values en las variables "Blind_Make","Blind_Model" y "Blind_Submodel", para estas variables el número de niveles es muy elevado. Como máximo las variables pueden tener 50 categorías diferentes. Vamos a realizar 3 operaciones para conseguir implementar los missing values:

```{r}
length(unique(train$Blind_Make))#75 levels
length(unique(train$Blind_Model))#1303 levels
length(unique(train$Blind_Submodel))#2740 levels
```

* Caso A: Utilizar toda la base de datos dejando en estas tres variables como "?" para que no lo detecte como missing value, pero teniendo en cuenta estas tres columnas para el resto de las observaciones.
* Caso B: Utilizar toda la base de datos quitando estas tres variables para la implementación de los missing values.
* Caso C: Quitar estas 8431 observaciones y realizar la implementación con el resto de las variables.

##Caso A:

```{r}
train[is.na(train$Blind_Make)] <- "?"
train[is.na(train$Blind_Model)] <- "?"
train[is.na(train$Blind_Submodel)] <- "?"

cols <- c("Calendar_Year","Model_Year","Blind_Make","Blind_Model","Blind_Submodel","Cat1","Cat2","Cat3","Cat4","Cat5","Cat6","Cat7","Cat8","Cat9","Cat10","Cat11","Cat12","OrdCat","Var1","Var2","Var3","Var4","Var5","Var6","Var7","Var8","NVCat","NVVar1","NVVar2","NVVar3","NVVar","Claim_Amount")
train_mice_A <- train[,4:35]
muestra_A <- train_mice_A[1:100000,]
imp <- mice(muestra_A, m=10,method= "polyreg", seed = 1234)


```

##Eliminamos Vehículos Duplicados
Para ello quitamos las variables Id (Row_ID,Vehicle,Calendar_Year). Dejamos Household_ID para tener algún identificador de la póliza (éste Id es igual para todos los vehiculos de esa casa)
```{r}
Data_noId <- train
Data_noId[,c("Row_ID","Household_ID","Vehicle","Calendar_Year","EdadVehiculo")] <- NULL
dim(Data_noId)

```
Tenemos vehículos duplicados pero cuyas Cat10,Cat11 y Cat12 varian en los diferentes año.

Correlación entre las variables:
```{r}
train_variables <- train[,5:34]
head(train_variables)
library(polycor)
hetcor(train_variables)
```


##Relaciona dos variables categóricas
cor(train$Calendar_Year,train$)
spineplot(train$Calendar_Year,train$Cat2)
spineplot(train$Calendar_Year,train$Cat3)
spineplot(train$Calendar_Year,train$Cat4)


##Muestra de Datos

El fichero "Train" que contiene datos de 2005, 2006 y 2007 tiene 13.184.290 observaciones y 35 columnas. De los cuales 95.605 han tenido siniestro con daño corporal.
```{r}
positiveclaim <- train[train$Claim_Amount>0,]
dim(positiveclaim)
```

Vamos a tomar una muestra del fichero "train" para trabajar los diferentes modelos y finalmente aplicarlo al fichero completo. Cogemos las 5.000.000 primeras filas.

```{r}
train_sample <- train[1:100000,]
class(train_sample)
train_sample <- as.data.frame(train_sample)
str(train_sample)
```


```{r}
library(plyr)
train_sample[6:20] <- lapply(train_sample[6:20], as.factor) 
train_sample$NVCat <- as.factor(train_sample$NVCat)
train_sample$OrdCat <- as.integer(train_sample$OrdCat)
train_sample$Model_Year <- as.factor(train_sample$Model_Year)
train_sample$Calendar_Year <- as.factor(train_sample$Calendar_Year)
```



Cuando el fichero ya está limpio lo divido en dos partes:

- 80000 observaciones "train"
- 20000 observaciones "test"

##KNN utilizando variables numéricas

```{r}
summary(train)
names(train_sample)
cols <- c("Cat8","Var1","Var2","Var3","Var4","Var5","Var6","Var7","Var8")
claims <- c("classification")
data_num <-train_sample[,cols]
head(data_num)
data_num_labels <- train$Claim_Amount[1:100000]
data_num_labels <- ifelse(train$Claim_Amount==0,"0","1")
data_num_labels <- as.factor(data_num_labels)
train_set_labels <- data_num_labels[1:80000]
test_set_labels <- data_num_labels[80001:100000]
library(class)
train_set <-data_num[1:80000,] 
test_set <- data_num[80001:100000,]
summary(train_set)
normalize <- function(x){return ((x-min(x))/(max(x)-min(x)))}
train_set_norm <- as.data.frame(lapply(train_set,normalize))
test_set_norm <- as.data.frame(lapply(test_set,normalize))
test_set[is.na(test_set$Cat8),] <- "A"
train_set[is.na(train_set$Cat8),] <- "A"
summary(test_set$Cat8)

prediccion <- knn(train=train_set,test=test_set,cl=train_set_labels,k=15)
```

#Clasificación K-vecinos (KNN)

El algoritmo KNN requiere que todas las variables sean categóricas o continuas. Enel caso de tener de los dos tipos, las categóricas deben ser transformadas a numéricas antes de aplicar el algoritmo. En el caso de que las categóricas tengan más de dos categorías usaremos variables dummy.
cor(train_sample)
```{r}
library(caret)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
head(train_sample)
class(train_sample)

pruebaknn <- train_sample[,c("Var1","Var2","Var3","Var4")]
class(pruebaknn$Cat1)
levels <- train_sample[,35]

levels <- ifelse(levels==0,"0","1")
levels <- as.factor(levels)
unique(levels)
count(levels)

pruebaknn_train <- pruebaknn[1:4000000,]
pruebaknn_test <- pruebaknn[4000001:5000000,]

train_levels <- levels[1:4000000]
test_levels <- levels[4000001:5000000]
class(test_levels)
pred <- knn(train=pruebaknn_train,test=pruebaknn_test,cl=train_levels,k=3,use.all = FALSE)
header <- unlist(strsplit(colnames(dummies), '[.]'))[2 * (1:ncol(dummies))]
Cat1 <- factor(dummies %*% 1:ncol(dummies), labels = header)
```
str(train_sample)
* Necesitamos normalizar los datos
* El objetivo es clasificar los datos en "si" tienen daño corporal o "no" tiene daño corporal




#problema de memoria
library(pryr)

```{r}
memory.limit()
object_size(train)
memory.limit(size=16384)
```
##Substituimos el importe por 0 o 1 (no importe - si importe)
prueba <- train[sample(nrow(train), 100000), ]
sum(prueba$Claim_Amount)
prueba$damage <- ifelse(prueba$Claim_Amount==0,"0","1")
prueba$damage <- as.factor(prueba$damage)
sum(prueba$Claim_Amount!=0)
sum(prueba$Claim_Amount)

###Número de casos con daño corporal.
sum(train$Claim_Amount==0)
sum(train$Claim_Amount!=0)
sum(prueba$Claim_Amount!=0)

#Vamos a trabajar inicialmente sobre una muestra de 2 millones de observaciones:
````{r}
train_sample <- train[sample(nrow(train), 2000000), ]
train_sample <- as.data.frame(train_sample)
dim(train_sample)
str(train_sample)

```


#Comprobacion filas duplicadas
```{r}
anyDuplicated(train_sample)
train_sample[duplicated(train_sample),]
head(train_sample)
```
##densidad

```{r}
install.packages("tigerstats")
library(tigerstats)
quantile(train_sample$Claim_Amount)
summary(train_sample$Claim_Amount)
quantile(train_sample$Claim_Amount,probs=c(0.85,0.99,1))
nrow(train_sample)
positiveclaim <- train_sample[train_sample$Claim_Amount>0,]
nrow(positiveclaim)

##Correlaciones entre variables???
cor(train_sample$Var1,train_sample$Var2)
cor(train_sample$Var1,train_sample$Var6)
CrossTable(x=train_sample$Cat1,y=train_sample$Cat2)

#de 2000000 solo 14517 han tenido siniestro, esto es el 0.7%
densityplot(~Claim_Amount,data=train_sample,
       xlab="Importe Reclamacion",
       main="Densidad Reclamaciones")
boxplot(train_sample$Claim_Amount,main="Importe Siniestros Daño Corporal",ylab="Importe")
```

write.csv(train, file = "train_clean.csv")
#Tratamiento?
str(train)
summary(train_sample$Blind_Make)

