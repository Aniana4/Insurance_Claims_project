---
title: "Claim Car Insurance"
author: "Montse Figueiro & Aniana González"
date: "6 de julio de 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##
The goal of this competition is to better predict Bodily Injury Liability Insurance claim payments based on the characteristics of the insured customer's vehicle.


* Cada Fila contiene la información anual sobre el seguro de un vehículo.  
* La variable "Claim_Amount" ha sido ajustada para tener en cuenta los efectos de las características no correspondientes al vehículo, pero pueden tener interacciones interesantes con las variables del vehículo.
* "Calendar_Year" es el año en el que el vehículo fué asegurado.
* "Household_ID" es la identificación del hogar, en un hogar puede haber más de un vehículo asegurado.
* "Vehicle" es el número que identifica al vehículo, pero el mismo vehículo no tiene porque tener el mismo número en los diferentes años.
* Tenemos para identifiar el vehículo Model_Year, Blind_Make (manufacturer), Blind_Model, Blind_Submodel.
* El resto de columnas contienen características del vehículo así como, otras características asociadas a la poliza.
* Las variables numéricas han sido normalizadas, tienen media 0 y desviación standar 1.
* Tenemos dos datasets:
    + Training de 2005-2007 para construir el modelo
    + Test de 2008-2009 sobre el que realizaremos las predicciones.

##Objetivo del Estudio

* Problema de Clasificación

Determinar que vehículos asegurados tendrán siniestros con daño corporal en los años 2008-2009, para ello utilizaremos el training dataset que nos aporta la información correspondiente a los años 2005-2006-2007, el cual volveremos a dividir en dos partes Training y Test data set para poder contrastar los resultados de la clasificación. Por último aplicaremos el modelo al Test dataset para 2008-2009.

    + K-vecinos (necesario normalizar)
    + Arboles de decisión (no necesario normalizar)
    + Bayes (Aprendizaje Probabilistico)
    + Random Forest
    + Validación: ROC, 

* Problema de Regresión

El objetivo del estudio es conseguir predecir en función de las características del vehículo los pagos por daño corporal ocasionados anualmente por cada vehículo.

    + Random Forest Regresión.
    + Previsión Datos numéricos - Métodos de Regresión
        + GLM
        + LM (PCA)
        + SVM
        + GBM
    + Neutral Networks
    
* Validación: Caret, ROC (visualización), Cross-validation, jackknife

Tipicamente en Seguros aplicamos los siguientes métodos:

Decision Trees, Random Forests, Gradient Boosting Machines, Neural Networks and Support Vector Machines

##Code Book Variables

[Dictionary](https://kaggle2.blob.core.windows.net/competitions-data/kaggle/2509/dictionary.html?sv=2012-02-12&se=2016-09-11T09%3A28%3A10Z&sr=b&sp=r&sig=LDorwQLrH%2BUJeduG58UByqlaxlatNMpte4iJZLhM0V8%3D)




##Lectura de Datos
```{}
library(data.table)
train <- fread("train_set.csv")
test <- read.csv("test_set.csv")
str(train)
summary(train)
```

###problema de memoria

```{r}
memory.limit()
memory.limit(size=45960)
```

###Cambiamos los tipos de variables:

Las categóricas pasan a Factor: 
```{r}
class(train)
train <- as.data.frame(train)
```

```{r}
library(plyr)
train[6:20] <- lapply(train[6:20], as.factor) 
train$NVCat <- as.factor(train$NVCat)
train$OrdCat <- as.factor(train$OrdCat)
```
----------------------------
Tenemos el año de la póliza y el año del vehículo, hemos comprobado que ninguna de las variables numérica se corresponde con la antigûedad del coche pero podemos calcularla y puede ser un dato muy interesante:

```{r}
train$EdadVehiculo <- as.numeric(train$Calendar_Year-train$Model_Year)
```
Tenemos valores negativos en la edad del vehículo, es decir que si el año de la póliza es 2005 el año del modelo es 2006:
Tenemos 155.991 coches con edades negativas,las vamos a dejar a 0 porque no tiene lógica 

```{r}
train$EdadVehiculo <- ifelse(train$EdadVehiculo<0,0,train$EdadVehiculo)
```
------------------------------
Tratamos a los ? como NA:
```{r}
train[train=="?"] <- NA
```

```{r}
#Prueba
library(dummies)
library(caret)
class(train)
train_2 <- train[complete.cases(train),]
str(train_2)
dmy <- dummyVars(" ~ Cat1+Cat2+Cat3+Cat4+Cat5+Cat6+Cat7+Cat8+Cat9+Cat10+Cat11+Cat12+OrdCat+NVCat", data = train_2)
train_3 <- data.frame(predict(dmy, newdata = train_2))
print(train_3)# filas 3726301 observaciones y 88 variables

write.csv(train_3, file="train_dummies.csv")

train_dummy <- cbind(train_2,train_3)
train_dummy$clasificacion <- as.factor(ifelse(train_dummy$Claim_Amount==0,"0","1"))
cols <- c("Calendar_Year","Model_Year" , "Var1", "Var2", "Var3", "Var4", "Var5", "Var6", "Var7", "Var8", "NVVar1", "NVVar2", "NVVar3", "NVVar4", "Cat1.A", "Cat1.B", "Cat1.C","Cat1.D", "Cat1.E", "Cat1.F", "Cat1.G", "Cat1.H", "Cat1.I", "Cat1.J", "Cat2.A", "Cat2.B", "Cat2.C", "Cat3.A", "Cat3.B", "Cat3.C", "Cat3.D", "Cat3.E", "Cat3.F",  "Cat4.A","Cat4.B","Cat4.C", "Cat5.A", "Cat5.B", "Cat5.C", "Cat6.B", "Cat6.C", "Cat6.D", "Cat6.E", "Cat6.F", "Cat7.A", "Cat7.B","Cat7.C", "Cat7.D", "Cat8.A", "Cat8.B", "Cat8.C", "Cat9.A", "Cat9.B", "Cat10.A", "Cat10.B","Cat10.C","Cat11.A", "Cat11.B", "Cat11.C", "Cat11.D", "Cat11.E", "Cat11.F", "Cat12.", "Cat12.A", "Cat12.B", "Cat12.C", "Cat12.D", "Cat12.E", "Cat12.F", "OrdCat.1", "OrdCat.2", "OrdCat.3", "OrdCat.4","OrdCat.5", "OrdCat.6", "OrdCat.7", "NVCat.A", "NVCat.B", "NVCat.C", "NVCat.D", "NVCat.E","NVCat.F", "NVCat.G", "NVCat.H", "NVCat.I","NVCat.J", "NVCat.K", "NVCat.L", "NVCat.M", "NVCat.N","NVCat.O","clasificacion")
#dput(names(entrenamiento))
train_dummy2 <- train_dummy[,cols]
prop.table(table(train_dummy2$clasificacion))

write.csv(train_dummy2, file="train_dummy2.csv")
```




Contamos los casos completos (no tienen ningún NA) y los casos incompletos (tienen algún NA)
```{r}
sum(complete.cases(train)) # Count of complete cases in a data frame named 'data'
sum(!complete.cases(train)) # Count of incomplete cases
```
Tenemos 9.457.989 observaciones con algún NA y 3.726.301 sin NA.

##Visualización de NA's
```{r}
library(VIM)
library(mice)
```
##Visualización con VIM de las variables con NA:

Tabla resumen Missing Values por Variable:
```{r}
Tabla_NAs <- as.data.frame(sapply(train, function(x) sum(is.na(x))))
colnames(Tabla_NAs) <- c("NumNAs")
Tabla_NAs$Porcentaje <- round((Tabla_NAs$NumNAs/nrow(train))*100,2)
```
Tenemos en total 23.438.318 de Missing Values, en el campo Porcentaje se indica el tanto por ciento de NA's sobre el total de observaciones de esa variable.

Seleccionamos de la tabla solo las variables que tienen NAs:
```{r}
TablaNas_Positive <- Tabla_NAs[Tabla_NAs$NumNAs>0,]
```
Como hemos comprobado en nuestra tabla "TablaNAs_Positive" solamente las variables categóricas tienen Missing Values:

|Variable|Número de NA|Porcentaje|
|--------|------------|----------|
|Blind_Make|        8431  |     0.06|
|Blind_Model|       8431  |     0.06|
|Blind_Submodel|    8431  |     0.06|
|Cat1           |  25981  |     0.20|
|Cat2   |        4874164  |    36.97|
|Cat3    |          3999  |     0.03|
|Cat4     |      5631649  |    42.71|
|Cat5      |     5637321  |    42.76|
|Cat6     |        25981  |     0.20|
|Cat7     |      7167634  |    54.36|
|Cat8      |        3364  |     0.03|
|Cat10      |       3917  |     0.03|
|Cat11       |     31469  |     0.24|
|OrdCat       |     7546  |     0.06|


```{r}
cols <- rownames(TablaNas_Positive)
cols_with_NA <- train[,cols]
```

```{r}
jpeg("Missing_Pattern.jpeg")
train_aggr = aggr(cols_with_NA, numbers=TRUE, sortVars=TRUE, labels=names(cols_with_NA), cex.axis=.7, gap=3, ylab=c("Proportion of missingness","Missingness Pattern"))
dev.off()
```

##Problema con "Imbalanced Training Data", más del 99% de los datos están clasificados como 0.

Tanto en el fichero Train como en el de Casos_Completos el 99% de los datos está clasificado como 0 con lo que cualquie predicción que hagamos nos va a dar 0.

```{r}    
data <- train
```

```{r}
data$Claim_Amount <- ifelse(data$Claim_Amount==0,"0","1")
prop.table(table(data$Claim_Amount))
```    
El 99,27% de las observaciones no tienen daño corporal, el 0,73%

##Multicolinealidad entre variables.

Blind_Submodel unido a Model_Year nos da el modelo exacto del vehículo y para un mismo modelo las catégoricas desde Cat1 a Cat9 son iguales.

Modelo k.7.3
```{r}
modelok73 <- train[train$Blind_Submodel=="K.7.3",]
cols <- c("Blind_Submodel","Model_Year","Cat1","Cat2","Cat3","Cat4","Cat5","Cat6","Cat7","Cat8","Cat9","Cat10","Cat11","Cat12","OrdCat")
modelok73 <- modelok73[,cols]
head(modelok73)
uniquemodelok73 <-lapply(modelok73,unique)
```

Para visualizar mejor el número de modelos diferentes que tenemos unificamos en una sola variable Blind_Submodel y Model_Year:

```{r}
train$Model <- as.factor(ifelse(is.na(train$Blind_Submodel),train$Blind_Submodel,paste(train$Blind_Submodel, as.factor(train$Model_Year), sep='')))
````

Agregado del Modelo, número de observaciones para cada Modelo:
```{r}
modelos <- as.data.frame(train$Model)
modelos$count <- as.numeric(1)
agregado_modelos <- aggregate(count~`train$Model`,modelos,sum)
agregado_modelos$count <- as.numeric(agregado_modelos$count)
dim(agregado_modelos)
#Añadimos una fila con los NA que la función aggregate excluye
modelos_NA <- train[is.na(train$Model),]
dim(modelos_NA)
newrow <- c("NA",8431)
agregado_modelos <- rbind(agregado_modelos,newrow)
agregado_modelos$count <- as.numeric(agregado_modelos$count)
head(agregado_modelos[order(-agregado_modelos[,2]), ])
dim(agregado_modelos)
```

Agregado de Blind_Submodel, observaciones con más Claim_Amount:

```{r}
agregado_claim_amount <- aggregate(Claim_Amount~Blind_Submodel+Model_Year,train,sum)
head(agregado_claim_amount[order(-agregado_claim_amount[,3]), ])
dim(agregado_claim_amount)
```

##Problemas que nos encontramos en nuestra base de datos:

* Número elevado de Missing Values
* Multicolinealidad 
* Unbalanced Data. 99% Claim_Amount = 0.
    * Under-Sampling: Eliminamos observaciones = 0, solo vale para ahorrar tiempo, perdemos información.
    * Over-Sampling: Implica hacer copias de la Clase mínima causando overfitting.
    * Este no suele ser un problema para la regressión logística.
    * Métodos de penalización como Ridge o Lasso funcionan bien en regressiones binomial.
    * logit and probit aproximan el 0 al mismo ratio que el 1.

##FICHERO TEST ANALISIS DE DATOS

ANALIZAMOS LAS CATEGORICAS EN EL FICHERO TEST (no hay missing values)
Los NA han sido eliminados del fichero test, vamos a cruzar los modelos de coche de test con el train.

El número de niveles que tenemos en las categóricas no es el mismo para el test que para el train:
```{}
summary(train$Cat1)
summary(test$Cat1)
```
```{r}
test$Model <- as.factor(ifelse(is.na(test$Blind_Submodel),test$Blind_Submodel,paste(test$Blind_Submodel, as.factor(test$Model_Year), sep='')))
````

```{r}
cols <- c("Cat1", "Cat2", "Cat3", "Cat4","Cat5" "Cat6", "Cat7", "Cat8", "Cat9", "Cat10","Cat11", "Cat12", "OrdCat", "Model")
test2 <- test[,cols]
modelos_test <- as.data.frame(test2)
modelos_test$count <- as.numeric(1)

agregado_modelos_test <-aggregate(count~Model+Cat1+Cat4+Cat6+Cat7,modelos_test,sum)
agregado_modelos_test$count <- as.numeric(agregado_modelos_test$count)
anyDuplicated(agregado_modelos_test$Model)
####agregado_modelos_test[agregado_modelos_test$Model=="Z.27.21999",]
head(agregado_modelos_test[order(-agregado_modelos_test[,6]),])
dim(agregado_modelos_test)#Agregando por Model y las categóricas cat1+cat4+cat5+cat6+cat7 nos da el mismo número de modelos.

str(test$Model)#tenemos 3646 modelos diferentes

#Merge with train, vamos a detectar los casos en los que el Modelo coincide en el fichero test y en el fichero train:
y <- merge(x = train, y = agregado_modelos_test , by = "Model", all.x = TRUE)
head(y)
casos_coincidentes <- y[!is.na(y$count),]
d <- count(unique(casos_coincidentes$Model))
sum(d$freq)#modelos que estan en train y en test
f <-count(unique(train$Model))
sum(f$freq) #modelos totales en train
g <- count(unique(test$Model))
sum(g$freq)#modelos totales en test
sum(complete.cases(casos_coincidentes)) # 3.725.632 están completos
sum(!complete.cases(casos_coincidentes))#48967 tienen NA
```


```{r}
#De los Casos_coincidentes hay 48967 observaciones en train que tienen NA y que podemos corregir:
pruebamerge_NA <- casos_coincidentes[!complete.cases(casos_coincidentes),]

```
##Tratamiento Missing values

Han sido borrados del Test dataset pero no del training dataset. Están como "?". 
¿¿Tenemos casillas en blanco???
Hay 4 variables con más de 4 millones de NA's


Hay 8431 observaciones con 48 siniestros con daño corporal a los que les falta Blind_Make, Blind_Model y Blind_Submodel:

```{r}
obs_without_model <- train[is.na(train$Blind_Submodel),]
dim(obs_without_model)
```

Sumamos cuantos NA tiene cada observación:
```{r}
NAS <- as.data.frame(rowSums(is.na(train)))
NAS$`rowSums(is.na(train))` <- as.factor(NAS$`rowSums(is.na(train))`)
```
3706301 casos no tienen NA y 3114961 tienen 1 NA.

##Sustitución NA categóricas

Las categóricas Cat1,Cat4, Cat5, Cat7,Cat8, Cat9 podemos agruparlas por Submodel y así poder corregir algunos de los NA que tenemos sustituyéndolos por el valor más frecuente para ese submodelo:

Queremos calcular la moda para Cat1, Cat4,Cat5,Cat7,Cat8,Cat9 para sustituir los NA:
```{r}
train2 <- train
Cat1 <- train[,c("Blind_Submodel","Cat1")]
Cat1 <- Cat1[complete.cases(Cat1),]
Cat4 <- train[,c("Blind_Submodel","Cat4")]
Cat4 <- Cat4[complete.cases(Cat4),]
Cat5 <- train[,c("Blind_Submodel","Cat5")]
Cat5 <- Cat5[complete.cases(Cat5),]
Cat7 <- train[,c("Blind_Submodel","Cat7")]
Cat7 <- Cat7[complete.cases(Cat7),]
Cat8 <- train[,c("Blind_Submodel","Cat8")]
Cat8 <- Cat8[complete.cases(Cat8),]

library(dplyr)
library(plyr)

#CAT1
a <- Cat1 %>% group_by(Blind_Submodel) %>% summarize (b =names(which.max(table(Cat1))))
a <- as.data.frame(a)
a$Blind_Submodel <- as.factor(a$Blind_Submodel)
a$b <- as.factor(a$b)
xy <- merge(x = train2, y = a, by = "Blind_Submodel", all.x = TRUE)
xy$Cat1[is.na(xy$Cat1)] <- as.factor(xy$b[is.na(xy$Cat1)])

#CAT4
b <- Cat4 %>% group_by(Blind_Submodel) %>% summarize (b =names(which.max(table(Cat4))))
b <- as.data.frame(b)
b$Blind_Submodel <- as.factor(b$Blind_Submodel)
b$b <- as.factor(b$b)
xy <- merge(x = xy, y = b, by = "Blind_Submodel", all.x = TRUE)
xy$Cat4[is.na(xy$Cat4)] <- as.factor(xy$b.y[is.na(xy$Cat4)])

#CAT5
d <- Cat5 %>% group_by(Blind_Submodel) %>% summarize (d =names(which.max(table(Cat5))))
d <- as.data.frame(d)
d$Blind_Submodel <- as.factor(d$Blind_Submodel)
d$d <- as.factor(d$d)
xy <- merge(x = xy, y = d, by = "Blind_Submodel", all.x = TRUE)
xy$Cat5[is.na(xy$Cat5)] <- as.factor(xy$d[is.na(xy$Cat5)])
summary(xy$Cat5)
summary(train$Cat5)

#CAT7

c <- Cat7 %>% group_by(Blind_Submodel) %>% summarize (b =names(which.max(table(Cat7))))
c <- as.data.frame(c)
c$Blind_Submodel <- as.factor(c$Blind_Submodel)
c$b <- as.factor(c$b)
xy <- merge(x = xy, y = c, by = "Blind_Submodel", all.x = TRUE)
xy$Cat7[is.na(xy$Cat7)] <- as.factor(xy$b[is.na(xy$Cat7)])
summary(xy$Cat7)
summary(train$Cat7)

#CAT8
f <- Cat8 %>% group_by(Blind_Submodel) %>% summarize (f =names(which.max(table(Cat8))))
f <- as.data.frame(f)
f$Blind_Submodel <- as.factor(f$Blind_Submodel)
f$f <- as.factor(f$f)
xy <- merge(x = xy, y = f, by = "Blind_Submodel", all.x = TRUE)
xy$Cat8[is.na(xy$Cat8)] <- as.factor(xy$f[is.na(xy$Cat8)])
summary(xy$Cat8)
summary(train$Cat8)
```
Elimino en xy las columnas que no necesito:
```{r}
xy$g <- NULL
xy$f <- NULL
xy$d <- NULL
xy$b <- NULL
xy$b.y <- NULL
```
Nuestro nuevo fichero de datos hemos conseguido limpiar más de 100000 observaciones.
```{r}
Data <- xy
sum(complete.cases(train))
sum(complete.cases(Data)) # Count of complete cases in a data frame named 'data'
sum(!complete.cases(Data)) # Count of incomplete cases

```

Hemos limpiado casi 1000 observaciones con daño corporal que se han quedado sin ningún NA:
```{r}

completeclaim <- xy[xy$Claim_Amount>0,]
dim(completeclaim)
comp <- completeclaim[complete.cases(completeclaim),]
dim(comp)
comp <- casos_completos[casos_completos$Claim_Amount>0,]
dim(comp)
```
VISUALIZACIÓN CON VIM DE SOLO LOS MISSING VALUES CASOS CON IMPORTE:
```{r}
library(VIM)
siniestros <- xy[xy$Claim_Amount>0,]
dput(names(xy))
cols <- c("Blind_Submodel", "Blind_Make", "Blind_Model", "Cat1", "Cat2", "Cat3", "Cat4", "Cat5","Cat6", "Cat7", "Cat8", "Cat9", "Cat10", "Cat11", "Cat12", "OrdCat")
siniestros <- siniestros[,cols]
train_aggr = aggr(siniestros, numbers=TRUE, sortVars=TRUE, labels=names(siniestros), cex.axis=.7, gap=3, ylab=c("Proportion of missingness","Missingness Pattern"))
```





ESQUEMA A REALIZAR:

Train >>> casos_completos >>> Sample_casos_completos >>> Eliminar ID >>> Partición Train/Test >>> Oversampling >>> "Data Frame compensado" >>> Eliminar Variables



CARET, partimos la base de datos en dos:
```{r}
library(caret)
set.seed(1234)
splitIndex <- createDataPartition(casos_completos$classification, p = .50,list = FALSE,times = 1)
train_sample <- casos_completos[ splitIndex,]
prop.table(table(train_sample$classification))
test_sample <- casos_completos[-splitIndex,]
test_sample_clas <- test_sample$classification
test_sample$classification <- NULL
```

SMOTE, over-resampling.

```{r}
library(DMwR)
train_SMOTE <- SMOTE(classification~.,train_sample,perc.over = 100,perc.under = 200)
prop.table(table(train_SMOTE$classification))
table(train_SMOTE$classification)
head(train_SMOTE)

```

--------------
ROSE para hacer el resampling de la base de datos, ,por defecto utiliza el método Both, una mezcla de Over and Under. El problema de ROSE son los datos que genera.
```{r}
library(ROSE)
train_ROSE <- ROSE(classification ~ ., data = train_sample, seed = 1)$data
table(train_ROSE$classification)
table(train_sample$classification)

```               
El train_sample tenía 20000 observaciones con 151 positivas. ROSE nos deja la base de datos con 10000 observaciones, las reduce pero nos amplia a 10000 las positivas.
--------------------

##Multicolinearidad de las variables, eliminación variables.

A partir de nuestra nueva base de datos creada con Rose y ya equilibrada, seleccionamos las variables que no tienen colinealidad:

CRAMER's V
```{r}
cv.test = function(x,y) {
  CV = sqrt(chisq.test(x, y, correct=FALSE)$statistic /
    (length(x) * (min(length(unique(x)),length(unique(y))) - 1)))
  print.noquote("Cramér V / Phi:")
  return(as.numeric(CV))
}

#Cramer V
with(train_SMOTE, cv.test(Cat1, Cat12))
```

correlationmatrix <- cor(train_SMOTE[,15:22])
correlationmatrix
highlyCorrelated <- findCorrelation(correlationmatrix, cutoff=0.5)
highlyCorrelated


Análisis modelos:

Blind_Submodel con más Claim_Amount:
```{r}
total_model <- aggregate(Claim_Amount~Blind_Submodel, train, sum)
Claim_model <- total_model[order(-total_model$Claim_Amount),] 
head(Claim_model,30)
```{r}
modeloau.14.0 <- train[train$Blind_Submodel=="AU.14.0",]
summary(modeloau.14.0)
```
Éste es el modelo de coche que más Claim_Amount tiene, hay 145474 observaciones. 
Con Summary vemos que Cat1, Cat4, Cat5, Cat7,Cat8,Cat9.















```{r}
require(plyr)
df1 <- ddply(casos_completos, c("Blind_Submodel","Cat1","Cat4","Cat5","Cat6","Cat7"), summarize, total=sum(Claim_Amount))
```

Categoricas:

```{r}
summary(train_SMOTE)
chisq.test(train_SMOTE$Cat4,train_SMOTE$Cat10)

#Interpretación Chi-test:
#Para las variables Cat10,Cat11 y Cat12 0.71,0.321 y 0.1287 no podemos rechazar la hipotesis nula de que las variables son independientes. Para el resto de las variables p-value es 0.

library(polycor)

pruebahetcor <- train_SMOTE[,c("Cat1","Cat2","Cat3","Cat4","Cat5","Cat6","Cat7","Cat8","Cat9","Cat10","Cat11","Cat12","OrdCat")]
#Interpretación 
corrhetcor <- hetcor(pruebahetcor)
corrhetcor$correlations


oneway.test(casos_completos$Claim_Amount~casos_completos$Var1, var.equal = TRUE)
```
VIF variables numéricas:
```{r}
dput(names(train_SMOTE))
model <- glm(classification~Model_Year+ Cat9+ Cat10+ Var4+ Var5+Var8+ NVVar2+ NVVar3,train_SMOTE, family=binomial(link=logit))
summary(model)
pred <- predict(model,test_sample)
model$coefficients
anova(model,test="Chisq")
install.packages("pscl")
library(pscl)
pR2(model)


Rsq = summary(model)$r.squared
Rsq
1/(1-Rsq)
```




Podemos prescindir de las variables "Blind_Make" y "Blind_Model" porque están incluidas dentro de "Blind_Submodel", hemos comprobado que Blind_Submodel incluye esas variables:
```{r}
pruebasubmodel <- train[train$Blind_Submodel=="K.2.4",]
summary(pruebasubmodel)
```





##Encontrar patrones de los Missing Values con "mice"

Tenemos 8431 observaciones que tienen missing values en las variables "Blind_Make","Blind_Model" y "Blind_Submodel", para estas variables el número de niveles es muy elevado. Como máximo las variables pueden tener 50 categorías diferentes. Vamos a realizar 3 operaciones para conseguir implementar los missing values:
Lo primero que vamos a hacer es separar train en dos data.frame vamos a quitar los 8451 observaciones el las que Submodel es NA porque al tener más de 2000 niveles nos da problemas a la hora de predecir el resto de las variables ya que Mice solo nos permite 50.
```{r}
train_1 <-  train[!is.na(train$Blind_Submodel),]
train_2 <- train[is.na(train$Blind_Submodel),]
dim(train_1)
dim(train_2)
```
seleccionamos solo las columnas con Missing Values para encontrar patrones, todas las variables son categóricas (Factor).

```{r}
train_Missing_Values <- train_1[,8:21]
unique(is.na(train_Missing_Values$Blind_Submodel))#no hay ningún NA en el submodel
train_Missing_Values_muestra <- train_Missing_Values[1:10000,]
patron_muestra <- md.pattern(train_Missing_Values_muestra)
```

##Imputación de los Missing Value con MICE

Con el data.frame que creamos con anterioridad ya podemos realizar la imputación de los missing Value con "mice":

```{r}
imp <- mice(data=train_Missing_Values_muestra, m=2,method= "polyreg", seed = 1234,MaxNWts = 2000)
```
El paquete mice tarda en exceso, así que probamos otro de los paquetes de R "Amelia"

install.packages("Amelia")
library(Amelia)
imp.amelia <- amelia(train_Missing_Values_muestra, noms=colnames(train_Missing_Values_muestra))
Vemos que 317 coches tienen los datos completos desde Cat1 a Cat9.


Añadir columna clasificación:
```{r}
train$classification <- ifelse(train$Claim_Amount==0,"0","1")
train$classification <- as.factor(train$classification)
```
##Comprobación de datos normalizados en variables numéricas (nosotros no hemos realizado la normalización pero tenemos que conocer que ha sido hecha):

```{r}
var_col <- c("Var1","Var2","Var3","Var4","Var5","Var6","Var7","Var8","NVVar1","NVVar2","NVVar3","NVVar4")
var_num <- train[,var_col]
round(sapply(var_num,function(x) mean(x)),0)
round(sapply(var_num,function(x) sd(x)),0)
```
##Visualización de Datos


Número de Pólizas por año
```{r}
count <- table(train$Calendar_Year)
df <- data.frame(group=names(count),count)
df$percent <-round((df$Freq/sum(df$Freq))*100,2)
df <- df[-1]
df
```
Pie Chart:
```{r}
slices <- df$Freq 
lbls <-df$Var1
pct <- df$percent
lbls <- paste("Año ",lbls, sep="")
lbls <- paste(lbls, pct,sep=": ") # add percents to labels 
lbls <- paste(lbls,"%",sep="") # ad % to labels 
pie(pct,labels = lbls, col=rainbow(length(lbls)),
  	main="Desglose Pólizas con Siniestro por Año")
```

Gráfico Variables categóricas - distribución tipo de variable:
```{r}
library(scales) 
gr2.a <- ggplot(train, aes(Cat1)) + 
 geom_bar(aes(Cat1, (..count..)/sum(..count..)), width=0.5, fill = "grey") 

gr2.a + scale_y_continuous(labels=percent) + xlab(NULL) + 
 ylab("% de tipos") + xlab("Tipos de Variable 1")+ggtitle("Distribución de las categorias") +  theme_bw()
```


summary(train$Row_ID)


Las 4 últimas variables no son variables del vehículo, con lo que se corresponden con variables de la póliza, podemos analizar en que casos la póliza ha tenido cobertura para daño corporal.
```{r}
claim_poliza <- aggregate(Claim_Amount ~ NVCat + NVVar1 + NVVar2 + NVVar3 + NVVar4, data = train, FUN = length)
head(claim_poliza[order(-claim_poliza$Claim_Amount),])
dim(claim_poliza)
claim_poliza_amount <- aggregate(Claim_Amount ~ NVCat + NVVar1 + NVVar2 + NVVar3 + NVVar4, data = train, FUN = sum)
head(claim_poliza_amount[order(-claim_poliza_amount$Claim_Amount),])
claim_poliza_class <- aggregate(Claim_Amount ~ classification + NVCat + NVVar1 + NVVar2 + NVVar3 + NVVar4, data = train, FUN = length)
head(claim_poliza_class[order(-claim_poliza_class$Claim_Amount),])

```


##Caso A:

```{r}
train[is.na(train$Blind_Make)] <- "?"
train[is.na(train$Blind_Model)] <- "?"
train[is.na(train$Blind_Submodel)] <- "?"

cols <- c("Calendar_Year","Model_Year","Blind_Make","Blind_Model","Blind_Submodel","Cat1","Cat2","Cat3","Cat4","Cat5","Cat6","Cat7","Cat8","Cat9","Cat10","Cat11","Cat12","OrdCat","Var1","Var2","Var3","Var4","Var5","Var6","Var7","Var8","NVCat","NVVar1","NVVar2","NVVar3","NVVar","Claim_Amount")
train_mice_A <- train[,4:35]
muestra_A <- train_mice_A[1:100000,]
imp <- mice(muestra_A, m=10,method= "polyreg", seed = 1234)


```

##Eliminamos Vehículos Duplicados
Para ello quitamos las variables Id (Row_ID,Vehicle,Calendar_Year). Dejamos Household_ID para tener algún identificador de la póliza (éste Id es igual para todos los vehiculos de esa casa)
```{r}
Data_noId <- train
Data_noId[,c("Row_ID","Household_ID","Vehicle","Calendar_Year","EdadVehiculo")] <- NULL
dim(Data_noId)

```
Tenemos vehículos duplicados pero cuyas Cat10,Cat11 y Cat12 varian en los diferentes año.

Correlación entre las variables:
```{r}
train_variables <- train[,5:34]
head(train_variables)
library(polycor)
hetcor(train_variables)
```


##Relaciona dos variables categóricas
cor(train$Calendar_Year,train$)
spineplot(train$Calendar_Year,train$Cat2)
spineplot(train$Calendar_Year,train$Cat3)
spineplot(train$Calendar_Year,train$Cat4)


##Muestra de Datos

El fichero "Train" que contiene datos de 2005, 2006 y 2007 tiene 13.184.290 observaciones y 35 columnas. De los cuales 95.605 han tenido siniestro con daño corporal.
```{r}
positiveclaim <- train[train$Claim_Amount>0,]
dim(positiveclaim)
```

Vamos a tomar una muestra del fichero "train" para trabajar los diferentes modelos y finalmente aplicarlo al fichero completo. Cogemos las 5.000.000 primeras filas.

```{r}
train_sample <- train[1:100000,]
class(train_sample)
train_sample <- as.data.frame(train_sample)
str(train_sample)
```


```{r}
library(plyr)
train_sample[6:20] <- lapply(train_sample[6:20], as.factor) 
train_sample$NVCat <- as.factor(train_sample$NVCat)
train_sample$OrdCat <- as.integer(train_sample$OrdCat)
train_sample$Model_Year <- as.factor(train_sample$Model_Year)
train_sample$Calendar_Year <- as.factor(train_sample$Calendar_Year)
```



Cuando el fichero ya está limpio lo divido en dos partes:

- 80000 observaciones "train"
- 20000 observaciones "test"

##KNN utilizando variables numéricas

```{r}
summary(train)
names(train_sample)
cols <- c("Cat8","Var1","Var2","Var3","Var4","Var5","Var6","Var7","Var8")
claims <- c("classification")
data_num <-train_sample[,cols]
head(data_num)
data_num_labels <- train$Claim_Amount[1:100000]
data_num_labels <- ifelse(train$Claim_Amount==0,"0","1")
data_num_labels <- as.factor(data_num_labels)
train_set_labels <- data_num_labels[1:80000]
test_set_labels <- data_num_labels[80001:100000]
library(class)
train_set <-data_num[1:80000,] 
test_set <- data_num[80001:100000,]
summary(train_set)
normalize <- function(x){return ((x-min(x))/(max(x)-min(x)))}
train_set_norm <- as.data.frame(lapply(train_set,normalize))
test_set_norm <- as.data.frame(lapply(test_set,normalize))
test_set[is.na(test_set$Cat8),] <- "A"
train_set[is.na(train_set$Cat8),] <- "A"
summary(test_set$Cat8)

prediccion <- knn(train=train_set,test=test_set,cl=train_set_labels,k=15)
```

#Clasificación K-vecinos (KNN)

El algoritmo KNN requiere que todas las variables sean categóricas o continuas. Enel caso de tener de los dos tipos, las categóricas deben ser transformadas a numéricas antes de aplicar el algoritmo. En el caso de que las categóricas tengan más de dos categorías usaremos variables dummy.
cor(train_sample)
```{r}
library(caret)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
train_sample$Cat1 <- predict(dummyVars(~ Cat1, data = train_sample), newdata = train_sample)
head(train_sample)
class(train_sample)

pruebaknn <- train_sample[,c("Var1","Var2","Var3","Var4")]
class(pruebaknn$Cat1)
levels <- train_sample[,35]

levels <- ifelse(levels==0,"0","1")
levels <- as.factor(levels)
unique(levels)
count(levels)

pruebaknn_train <- pruebaknn[1:4000000,]
pruebaknn_test <- pruebaknn[4000001:5000000,]

train_levels <- levels[1:4000000]
test_levels <- levels[4000001:5000000]
class(test_levels)
pred <- knn(train=pruebaknn_train,test=pruebaknn_test,cl=train_levels,k=3,use.all = FALSE)
header <- unlist(strsplit(colnames(dummies), '[.]'))[2 * (1:ncol(dummies))]
Cat1 <- factor(dummies %*% 1:ncol(dummies), labels = header)
```
str(train_sample)
* Necesitamos normalizar los datos
* El objetivo es clasificar los datos en "si" tienen daño corporal o "no" tiene daño corporal




#problema de memoria
library(pryr)

```{r}
memory.limit()
object_size(train)
memory.limit(size=16384)
```
##Substituimos el importe por 0 o 1 (no importe - si importe)
prueba <- train[sample(nrow(train), 100000), ]
sum(prueba$Claim_Amount)
prueba$damage <- ifelse(prueba$Claim_Amount==0,"0","1")
prueba$damage <- as.factor(prueba$damage)
sum(prueba$Claim_Amount!=0)
sum(prueba$Claim_Amount)

###Número de casos con daño corporal.
sum(train$Claim_Amount==0)
sum(train$Claim_Amount!=0)
sum(prueba$Claim_Amount!=0)

#Vamos a trabajar inicialmente sobre una muestra de 2 millones de observaciones:
````{r}
train_sample <- train[sample(nrow(train), 2000000), ]
train_sample <- as.data.frame(train_sample)
dim(train_sample)
str(train_sample)

```


#Comprobacion filas duplicadas
```{r}
anyDuplicated(train_sample)
train_sample[duplicated(train_sample),]
head(train_sample)
```
##densidad

```{r}
install.packages("tigerstats")
library(tigerstats)
quantile(train_sample$Claim_Amount)
summary(train_sample$Claim_Amount)
quantile(train_sample$Claim_Amount,probs=c(0.85,0.99,1))
nrow(train_sample)
positiveclaim <- train_sample[train_sample$Claim_Amount>0,]
nrow(positiveclaim)

##Correlaciones entre variables???
cor(train_sample$Var1,train_sample$Var2)
cor(train_sample$Var1,train_sample$Var6)
CrossTable(x=train_sample$Cat1,y=train_sample$Cat2)

#de 2000000 solo 14517 han tenido siniestro, esto es el 0.7%
densityplot(~Claim_Amount,data=train_sample,
       xlab="Importe Reclamacion",
       main="Densidad Reclamaciones")
boxplot(train_sample$Claim_Amount,main="Importe Siniestros Daño Corporal",ylab="Importe")
```

write.csv(train, file = "train_clean.csv")
#Tratamiento?
str(train)
summary(train_sample$Blind_Make)

